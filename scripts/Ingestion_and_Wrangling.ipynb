{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages\n",
    "\n",
    "This script makes use of the packages below.  \n",
    "* \"os\" is only required if you want to specify a local folder in which to save an output (e.g., CSV or image file).\n",
    "* 'sqlalchemy' is used to create a connection engine to our Postgres database.\n",
    "* 'pandas' allows us to query our database using SQL while arraying our data calls into dataframes.\n",
    "* 'numpy', 'seaborn', and 'matplotlib' are used for visualization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set working directory (optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the working directory.\n",
    "os.chdir('C:/Users/dnavarr/Documents/Python Scripts/used_cars/scripts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to our database.\n",
    "This code uses the 'create_engine' function from 'sqlalchemy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://[USER]@[IP]/[DATABASE]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import our data.\n",
    "We will make separate queries to our database to retreive data from our different tables.\n",
    "\n",
    "For purposes of this exercise, I am making separate calls to each of our tables and later merging data using 'pandas'.\n",
    "\n",
    "In a future iteration, we could make the joins at the import level using SQL.  \n",
    "\n",
    "But for now, I'm doing this with Python/pandas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import MarketCheck Honda data subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              vin_ss vehicle_type_ss body_type_ss make_ss model_ss  year_is  \\\n",
      "0  3CZRM3H39FG709908             SUV          SUV   HONDA     CR-V     2015   \n",
      "1  5FNYF6H52HB021773             SUV          SUV   HONDA    PILOT     2017   \n",
      "2  2HGFB2F5XFH503740             Car        Sedan   HONDA    CIVIC     2015   \n",
      "3  1HGCR2F82FA080126             Car        Sedan   HONDA   ACCORD     2015   \n",
      "4  1HGCR2F82FA080126             Car        Sedan   HONDA   ACCORD     2015   \n",
      "\n",
      "       fuel_type_ss engine_size_ss transmission_ss doors_is  ...   miles_fs  \\\n",
      "0  Regular Unleaded            2.4       Automatic        4  ...      35708   \n",
      "1  Regular Unleaded            3.5                        4  ...      58628   \n",
      "2  Regular Unleaded            1.8       Automatic        4  ...      41669   \n",
      "3  Regular Unleaded            2.4       Automatic        4  ...      18539   \n",
      "4  Regular Unleaded            2.4       Automatic        4  ...      18539   \n",
      "\n",
      "  latitude_fs longitude_fs    city_ss  state_ss  dealer_id_is  \\\n",
      "0                           Stoughton        WS       1096169   \n",
      "1                           Stoughton        WS       1096169   \n",
      "2                           Stoughton        WS       1096169   \n",
      "3       18.42       -66.07   Hato Rey        PR       1019302   \n",
      "4        18.4       -66.06   Hato Rey        PR       1019299   \n",
      "\n",
      "  seller_comments_length options_length features_length dom_is  \n",
      "0                    648              0            1098     62  \n",
      "1                   1077              0            1503     49  \n",
      "2                   1325              0             981     56  \n",
      "3                      0              0            3040     37  \n",
      "4                      0           1297            3040     38  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# I tested this script by querying only \"Honda\" vehicles. \n",
    "\n",
    "# If you want to query a different make, modify the \"WHERE\" clause.\n",
    "\n",
    "marketcheck = pd.read_sql_query(\"\"\"\n",
    "SELECT\n",
    "vin_ss,\n",
    "vehicle_type_ss,\n",
    "body_type_ss,\n",
    "UPPER(make_ss) AS \"make_ss\",\n",
    "UPPER(model_ss) AS \"model_ss\",\n",
    "NULLIF(year_is, '')::int AS \"year_is\",\n",
    "fuel_type_ss,\n",
    "engine_size_ss,\n",
    "transmission_ss,\n",
    "doors_is,\n",
    "cylinders_is,\n",
    "interior_color_ss,\n",
    "exterior_color_ss,\n",
    "LPAD(zip_is, 5, '0') AS \"zipcode\",\n",
    "NULLIF(price_fs, '')::int AS \"price_fs\",\n",
    "NULLIF(miles_fs, '')::int AS \"miles_fs\",\n",
    "latitude_fs,\n",
    "longitude_fs,\n",
    "city_ss,\n",
    "state_ss,\n",
    "dealer_id_is,\n",
    "char_length(seller_comments_texts) AS \"seller_comments_length\",\n",
    "char_length(options_texts) AS \"options_length\",\n",
    "char_length(features_texts) AS \"features_length\",\n",
    "dom_is\n",
    "FROM listings\n",
    "WHERE\n",
    "  (upper(make_ss) LIKE 'HONDA' AND price_fs <>'')\n",
    "  AND (upper(make_ss) LIKE 'HONDA' AND miles_fs <>'')\n",
    "  AND (upper(make_ss) LIKE 'HONDA' AND model_ss <>'')\n",
    "ORDER BY\n",
    "  zipcode,\n",
    "  state_ss\n",
    ";\n",
    "\"\"\", con=engine)\n",
    "\n",
    "print(marketcheck.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import City Data\n",
    "\n",
    "MarketCheck's vehicle listing data includes ZIP code, city, and state information.  \n",
    "\n",
    "The 'cities_extended' dataset will allow us to identify corresponding county information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        city state_code    zip   latitude   longitude     county\n",
      "0   Adjuntas         PR  00601    18.1788    -66.7516   Adjuntas\n",
      "1     Aguada         PR  00602  18.381389  -67.188611     Aguada\n",
      "2  Aguadilla         PR  00603    18.4554    -67.1308  Aguadilla\n",
      "3  Aguadilla         PR  00604    18.4812    -67.1467  Aguadilla\n",
      "4  Aguadilla         PR  00605  18.429444  -67.154444  Aguadilla\n"
     ]
    }
   ],
   "source": [
    "cities = pd.read_sql_query(\"\"\"\n",
    "                               SELECT *\n",
    "                               FROM cities_extended;\n",
    "                               \"\"\", con=engine)\n",
    "\n",
    "print(cities.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Census FIPS Code Data\n",
    "\n",
    "Because county names might be misspelled across different datasets (e.g., \"Saint\" vs. \"St.\" vs \"St\"), we will use the national FIPS standard.  \n",
    "\n",
    "Each county in each state is coded with its own unique FIPS code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  state county_name fips_code\n",
      "0    AL     Autauga     01001\n",
      "1    AL     Baldwin     01003\n",
      "2    AL     Barbour     01005\n",
      "3    AL        Bibb     01007\n",
      "4    AL      Blount     01009\n"
     ]
    }
   ],
   "source": [
    "census_fips = pd.read_sql_query(\"\"\"\n",
    "SELECT\n",
    "state,   \n",
    "county_name,  \n",
    "LPAD(fips, 5, '0') AS \"fips_code\"\n",
    "FROM census_fips;\"\"\",\n",
    "con=engine)\n",
    "\n",
    "print(census_fips.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import BEA Regions\n",
    "\n",
    "As we would like to consider geographic regions for analysis, we will use the BEA-defined regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   state_code     state_name state_abbrev  region_code         region_name  \\\n",
      "0           9    Connecticut           CT            1  New England Region   \n",
      "1          23          Maine           ME            1  New England Region   \n",
      "2          25  Massachusetts           MA            1  New England Region   \n",
      "3          33  New Hampshire           NH            1  New England Region   \n",
      "4          44   Rhode Island           RI            1  New England Region   \n",
      "\n",
      "  region_abbrev  region_id  \n",
      "0          NENG         91  \n",
      "1          NENG         91  \n",
      "2          NENG         91  \n",
      "3          NENG         91  \n",
      "4          NENG         91  \n"
     ]
    }
   ],
   "source": [
    "regions = pd.read_sql_query(\"\"\"\n",
    "                                SELECT *\n",
    "                                FROM bea_regions;\n",
    "                                \"\"\", con=engine)\n",
    "\n",
    "print(regions.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Census/BLS metropolitan and non-metropolitan data.\n",
    "\n",
    "We will bring in a dataset that will allow us to identify each listing's corresponding MSA designation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  zip_code   fips        locality_name        state     cbsa  \\\n",
      "0    00601  72001   Adjuntas Municipio  Puerto Rico  7200001   \n",
      "1    00601  72141     Utuado Municipio  Puerto Rico  7200001   \n",
      "2    00602  72003     Aguada Municipio  Puerto Rico    10380   \n",
      "3    00603  72005  Aguadilla Municipio  Puerto Rico    10380   \n",
      "4    00606  72093    Maricao Municipio  Puerto Rico  7200001   \n",
      "\n",
      "                              msa_name  \n",
      "0   Puerto Rico nonmetropolitan area 1  \n",
      "1   Puerto Rico nonmetropolitan area 1  \n",
      "2  Aguadilla-Isabela-San Sebastian, PR  \n",
      "3  Aguadilla-Isabela-San Sebastian, PR  \n",
      "4   Puerto Rico nonmetropolitan area 1  \n"
     ]
    }
   ],
   "source": [
    "locality = pd.read_sql_query(\"\"\"\n",
    "                               SELECT *\n",
    "                               FROM locality;\n",
    "                               \"\"\", con=engine)\n",
    "\n",
    "print(locality.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will do a bit of wrangling to reduce the scope of our Census MSA data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "634019"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows:\n",
    "len(locality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42451"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop place names from the locality dataframe, \n",
    "# otherwise our data explodes (as county can have multiple zips, cities, etc.)\n",
    "locality = locality.drop('locality_name', axis=1)\n",
    "\n",
    "# Define whether an MSA is a Micropolitan Division.\n",
    "locality['msa_type'] = np.where(locality['msa_name'].str.contains(\"Division\"), \"Division\", \"\")\n",
    "\n",
    "# Drop if it is a Division as this will create a lot of duplicative data.\n",
    "# For example, there are 2 Micropolitan Divisions within the DC/MD/VA Metropolitan MSA.\n",
    "# By keeping the Micropolitan Divisions, we'd be replicating each DC-area car listing by 3.\n",
    "locality = locality[locality.msa_type != \"Division\"]\n",
    "\n",
    "# Designate whether the MSA is a Metropolitan or Non-Metropolitan\n",
    "locality['msa_type'] = np.where(locality['msa_name'].str.contains(\"nonmetropolitan\"), \n",
    "                                \"Non-Metropolitan\", \"Metropolitan\")\n",
    "\n",
    "# We will drop duplicates.\n",
    "locality = locality.drop_duplicates()\n",
    "\n",
    "# Number of rows:\n",
    "len(locality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  zip_code   fips        state     cbsa                             msa_name  \\\n",
      "0    00601  72001  Puerto Rico  7200001   Puerto Rico nonmetropolitan area 1   \n",
      "1    00601  72141  Puerto Rico  7200001   Puerto Rico nonmetropolitan area 1   \n",
      "2    00602  72003  Puerto Rico    10380  Aguadilla-Isabela-San Sebastian, PR   \n",
      "3    00603  72005  Puerto Rico    10380  Aguadilla-Isabela-San Sebastian, PR   \n",
      "4    00606  72093  Puerto Rico  7200001   Puerto Rico nonmetropolitan area 1   \n",
      "\n",
      "           msa_type  \n",
      "0  Non-Metropolitan  \n",
      "1  Non-Metropolitan  \n",
      "2      Metropolitan  \n",
      "3      Metropolitan  \n",
      "4  Non-Metropolitan  \n"
     ]
    }
   ],
   "source": [
    "print(locality.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring in SOI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  state zipcode  agi_stub      n1   mars1   mars2       n2  numdep    ral  \\\n",
      "0    AL       0         1  815440  477700  105350  1296920  491310  31550   \n",
      "1    AL       0         2  495830  211930  142340   996240  360480  11770   \n",
      "2    AL       0         3  263390   83420  137870   584000  182880    150   \n",
      "3    AL       0         4  167190   29420  124060   421720  130160      0   \n",
      "4    AL       0         5  217440   20240  188080   601040  195990      0   \n",
      "\n",
      "      rac   ...      a02650  n26270  a03220  n03300  n03210  n03230  schf  \\\n",
      "0  225140   ...    10787121    7900     308      40   17110    6620  8310   \n",
      "1  118460   ...    18020908   10340    3476      90   41490    2340  8920   \n",
      "2   41910   ...    16351320   11580    2146     190   29110    2150  8470   \n",
      "3   18560   ...    14646693    8780    2323     110   20610     360  5510   \n",
      "4   11620   ...    29696755   24980    3192    1310   22870    3450  8180   \n",
      "\n",
      "   n18800  n19300  n19700  \n",
      "0   25020   20950   36370  \n",
      "1   64360   60550   85920  \n",
      "2   68320   71760   85510  \n",
      "3   58540   64200   70730  \n",
      "4  117980  128400  139560  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "####  SOI Data\n",
    "soi_data = pd.read_sql_query(\"\"\"\n",
    "                                 SELECT\n",
    "                                 STATE,\n",
    "                                 ZIPCODE,\n",
    "                                 AGI_STUB,\n",
    "                                 N1,\n",
    "                                 MARS1,\n",
    "                                 MARS2,\n",
    "                                 N2,\n",
    "                                 NUMDEP,\n",
    "                                 RAL,\n",
    "                                 RAC,\n",
    "                                 ELDERLY,\n",
    "                                 A00100,\n",
    "                                 A02650,\n",
    "                                 N26270,\n",
    "                                 A03220,\n",
    "                                 N03300,\n",
    "                                 N03210,\n",
    "                                 N03230,\n",
    "                                 SCHF,\n",
    "                                 N18800,\n",
    "                                 N19300,\n",
    "                                 N19700                       \n",
    "                                 FROM irs_soi_full;\n",
    "                                 \"\"\", con=engine)\n",
    "\n",
    "print(soi_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe Merging (joins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge our listings dataframe with our cities data using ZIP code and state.\n",
    "listings = pd.merge(marketcheck, cities, left_on=['state_ss', 'zipcode'], right_on=['state_code', 'zip'])\n",
    "\n",
    "# Merge listings with Census FIPS codes.\n",
    "listings = pd.merge(listings, census_fips, left_on=['state_ss', 'county',], right_on=['state', 'county_name'])\n",
    "\n",
    "# Merge regions into our listings dataframe.\n",
    "listings = pd.merge(listings, regions, left_on='state_code', right_on='state_abbrev')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge our listings dataframe with the locality dataset.\n",
    "# Even though we eliminated Micropolitan divisions, our data still explodes due to the high number of zip codes.\n",
    "# This step might be memory intensive as it creates a dataframe with over 11 million rows.\n",
    "listings = pd.merge(listings, locality, left_on='fips_code', right_on='fips')\n",
    "\n",
    "# We drop duplicate columns that resulted from our dataframe merges.\n",
    "listings = listings.drop(['zip', 'zip_code', 'city', 'state_code_x', 'state_x', \n",
    "                          'county_name', 'state_code_y', 'state_name', 'state_abbrev', \n",
    "                          'fips', 'state_y'], axis=1)\n",
    "\n",
    "# We drop duplicate rows.  This should bring our dataframe down from 11 million rows to about 300,000 (for Honda).\n",
    "listings = listings.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge county names to SOI data.\n",
    "soi_data = pd.merge(soi_data, cities, left_on=['state', 'zipcode'], right_on=['state_code', 'zip'])\n",
    "\n",
    "soi_data = soi_data.groupby(['zipcode']).sum().reset_index()\n",
    "\n",
    "listings = pd.merge(listings, soi_data, left_on=['zipcode'], right_on=['zipcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CLEAN-UP for Memory; \n",
    "del(census_fips, cities, marketcheck, regions, locality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              vin_ss vehicle_type_ss body_type_ss make_ss model_ss  year_is  \\\n",
      "0  19XFB2F84FE201705             Car        Sedan   HONDA    CIVIC     2015   \n",
      "1  5J6RM4H95GL033651             SUV          SUV   HONDA     CR-V     2016   \n",
      "2  2HKRM4H54DH671649             SUV          SUV   HONDA     CR-V     2013   \n",
      "3  2HGFC4B01HH310897             Car        Coupe   HONDA    CIVIC     2017   \n",
      "4  SHHFK7H59JU404168             Car    Hatchback   HONDA    CIVIC     2018   \n",
      "\n",
      "       fuel_type_ss engine_size_ss                     transmission_ss  \\\n",
      "0  Regular Unleaded            1.8                           Automatic   \n",
      "1  Regular Unleaded            2.4                           Automatic   \n",
      "2  Regular Unleaded            2.4                           Automatic   \n",
      "3  Regular Unleaded            2.0                           Automatic   \n",
      "4          Gasoline            1.5  Continuously Variable Transmission   \n",
      "\n",
      "  doors_is  ...    a02650 n26270 a03220 n03300  n03210  n03230 schf n18800  \\\n",
      "0        4  ...     92031     70     13      0      80       0    0     20   \n",
      "1        4  ...    581152    540     93    100     620      80   40    150   \n",
      "2        4  ...    581152    540     93    100     620      80   40    150   \n",
      "3        2  ...    135375     90     17      0     200       0    0     50   \n",
      "4        4  ...    135375     90     17      0     200       0    0     50   \n",
      "\n",
      "  n19300 n19700  \n",
      "0    320    430  \n",
      "1   2160   2570  \n",
      "2   2160   2570  \n",
      "3    560    710  \n",
      "4    560    710  \n",
      "\n",
      "[5 rows x 56 columns]\n",
      "279193\n"
     ]
    }
   ],
   "source": [
    "print(listings.head())\n",
    "\n",
    "print(len(listings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorts listings from most days on the market to least\n",
    "listings_sorted = listings.sort_values('dom_is', ascending = False)\n",
    "\n",
    "#drops duplicate vin numbers keeping first (longest on market) vin\n",
    "listings = listings_sorted.drop_duplicates(subset='vin_ss', keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75056\n"
     ]
    }
   ],
   "source": [
    "print(len(listings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding\n",
    "\n",
    "We will encode our categorical data into numerics so that we can use scikit-learn and seaborn packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dnavarr\\AppData\\Local\\Continuum\\anaconda3\\envs\\alpastor\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "### Label Encoding\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# We create a label (category) encoder object using scikit-learn's \"le\" \n",
    "# naming convention (based on their documentation).\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Fit the encoder to the pandas column\n",
    "le.fit(listings['model_ss'])\n",
    "\n",
    "# View the labels\n",
    "list(le.classes_)\n",
    "\n",
    "# Transform the Categories into Integers\n",
    "le.transform(listings['model_ss'])\n",
    "\n",
    "# Append to our dataframe.\n",
    "listings['model_ss_encoded'] = le.transform(listings['model_ss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat label encoding process for each categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dnavarr\\AppData\\Local\\Continuum\\anaconda3\\envs\\alpastor\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\dnavarr\\AppData\\Local\\Continuum\\anaconda3\\envs\\alpastor\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\dnavarr\\AppData\\Local\\Continuum\\anaconda3\\envs\\alpastor\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\dnavarr\\AppData\\Local\\Continuum\\anaconda3\\envs\\alpastor\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\dnavarr\\AppData\\Local\\Continuum\\anaconda3\\envs\\alpastor\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\dnavarr\\AppData\\Local\\Continuum\\anaconda3\\envs\\alpastor\\lib\\site-packages\\ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\dnavarr\\AppData\\Local\\Continuum\\anaconda3\\envs\\alpastor\\lib\\site-packages\\ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\dnavarr\\AppData\\Local\\Continuum\\anaconda3\\envs\\alpastor\\lib\\site-packages\\ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\dnavarr\\AppData\\Local\\Continuum\\anaconda3\\envs\\alpastor\\lib\\site-packages\\ipykernel_launcher.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\dnavarr\\AppData\\Local\\Continuum\\anaconda3\\envs\\alpastor\\lib\\site-packages\\ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\dnavarr\\AppData\\Local\\Continuum\\anaconda3\\envs\\alpastor\\lib\\site-packages\\ipykernel_launcher.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\dnavarr\\AppData\\Local\\Continuum\\anaconda3\\envs\\alpastor\\lib\\site-packages\\ipykernel_launcher.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\dnavarr\\AppData\\Local\\Continuum\\anaconda3\\envs\\alpastor\\lib\\site-packages\\ipykernel_launcher.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\dnavarr\\AppData\\Local\\Continuum\\anaconda3\\envs\\alpastor\\lib\\site-packages\\ipykernel_launcher.py:97: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\dnavarr\\AppData\\Local\\Continuum\\anaconda3\\envs\\alpastor\\lib\\site-packages\\ipykernel_launcher.py:104: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# make_ss\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(listings['make_ss'])\n",
    "list(le.classes_)\n",
    "le.transform(listings['make_ss'])\n",
    "listings['make_ss_encoded'] = le.transform(listings['make_ss'])\n",
    "\n",
    "# body_type_ss\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(listings['body_type_ss'])\n",
    "list(le.classes_)\n",
    "le.transform(listings['body_type_ss'])\n",
    "listings['body_type_ss_encoded'] = le.transform(listings['body_type_ss'])\n",
    "\n",
    "# vehicle_type_ss\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(listings['vehicle_type_ss'])\n",
    "list(le.classes_)\n",
    "le.transform(listings['vehicle_type_ss'])\n",
    "listings['vehicle_type_ss_encoded'] = le.transform(listings['vehicle_type_ss'])\n",
    "\n",
    "# fuel_type_ss\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(listings['fuel_type_ss'])\n",
    "list(le.classes_)\n",
    "le.transform(listings['fuel_type_ss'])\n",
    "listings['fuel_type_ss_encoded'] = le.transform(listings['fuel_type_ss'])\n",
    "\n",
    "# engine_size_ss\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(listings['engine_size_ss'])\n",
    "list(le.classes_)\n",
    "le.transform(listings['engine_size_ss'])\n",
    "listings['engine_size_ss_encoded'] = le.transform(listings['engine_size_ss'])\n",
    "\n",
    "# transmission_ss\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(listings['transmission_ss'])\n",
    "list(le.classes_)\n",
    "le.transform(listings['transmission_ss'])\n",
    "listings['transmission_ss_encoded'] = le.transform(listings['transmission_ss'])\n",
    "\n",
    "# doors_is\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(listings['doors_is'])\n",
    "list(le.classes_)\n",
    "le.transform(listings['doors_is'])\n",
    "listings['doors_is_encoded'] = le.transform(listings['doors_is'])\n",
    "\n",
    "# cylinders_is\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(listings['cylinders_is'])\n",
    "list(le.classes_)\n",
    "le.transform(listings['cylinders_is'])\n",
    "listings['cylinders_is_encoded'] = le.transform(listings['cylinders_is'])\n",
    "\n",
    "# interior_color_ss\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(listings['interior_color_ss'])\n",
    "list(le.classes_)\n",
    "le.transform(listings['interior_color_ss'])\n",
    "listings['interior_color_ss_encoded'] = le.transform(listings['interior_color_ss'])\n",
    "\n",
    "# exterior_color_ss\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(listings['exterior_color_ss'])\n",
    "list(le.classes_)\n",
    "le.transform(listings['exterior_color_ss'])\n",
    "listings['exterior_color_ss_encoded'] = le.transform(listings['exterior_color_ss'])\n",
    "\n",
    "# state_ss\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(listings['state_ss'])\n",
    "list(le.classes_)\n",
    "le.transform(listings['state_ss'])\n",
    "listings['state_ss_encoded'] = le.transform(listings['state_ss'])\n",
    "\n",
    "# county_name\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(listings['county'])\n",
    "list(le.classes_)\n",
    "le.transform(listings['county'])\n",
    "listings['county_encoded'] = le.transform(listings['county'])\n",
    "\n",
    "# fips_code\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(listings['fips_code'])\n",
    "list(le.classes_)\n",
    "le.transform(listings['fips_code'])\n",
    "listings['fips_code_encoded'] = le.transform(listings['fips_code'])\n",
    "\n",
    "# msa_type\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(listings['msa_type'])\n",
    "list(le.classes_)\n",
    "le.transform(listings['msa_type'])\n",
    "listings['msa_type_encoded'] = le.transform(listings['msa_type'])\n",
    "\n",
    "# msa_name\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(listings['msa_name'])\n",
    "list(le.classes_)\n",
    "le.transform(listings['msa_name'])\n",
    "listings['msa_name_encoded'] = le.transform(listings['msa_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_is</th>\n",
       "      <th>price_fs</th>\n",
       "      <th>miles_fs</th>\n",
       "      <th>seller_comments_length</th>\n",
       "      <th>options_length</th>\n",
       "      <th>features_length</th>\n",
       "      <th>dom_is</th>\n",
       "      <th>region_code</th>\n",
       "      <th>region_id</th>\n",
       "      <th>agi_stub</th>\n",
       "      <th>...</th>\n",
       "      <th>doors_is_encoded</th>\n",
       "      <th>cylinders_is_encoded</th>\n",
       "      <th>interior_color_ss_encoded</th>\n",
       "      <th>exterior_color_ss_encoded</th>\n",
       "      <th>state_ss_encoded</th>\n",
       "      <th>county_encoded</th>\n",
       "      <th>fips_code_encoded</th>\n",
       "      <th>msa_type_encoded</th>\n",
       "      <th>msa_name_encoded</th>\n",
       "      <th>zscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>75056.000000</td>\n",
       "      <td>75056.000000</td>\n",
       "      <td>7.505600e+04</td>\n",
       "      <td>75056.000000</td>\n",
       "      <td>75056.000000</td>\n",
       "      <td>75056.000000</td>\n",
       "      <td>75056.000000</td>\n",
       "      <td>75056.000000</td>\n",
       "      <td>75056.000000</td>\n",
       "      <td>75056.0</td>\n",
       "      <td>...</td>\n",
       "      <td>75056.000000</td>\n",
       "      <td>75056.000000</td>\n",
       "      <td>75056.000000</td>\n",
       "      <td>75056.000000</td>\n",
       "      <td>75056.000000</td>\n",
       "      <td>75056.000000</td>\n",
       "      <td>75056.000000</td>\n",
       "      <td>75056.000000</td>\n",
       "      <td>75056.000000</td>\n",
       "      <td>75056.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2013.311434</td>\n",
       "      <td>17352.138510</td>\n",
       "      <td>6.510163e+04</td>\n",
       "      <td>660.293980</td>\n",
       "      <td>746.204674</td>\n",
       "      <td>2380.702396</td>\n",
       "      <td>97.369204</td>\n",
       "      <td>4.942483</td>\n",
       "      <td>94.942483</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.896797</td>\n",
       "      <td>5.133074</td>\n",
       "      <td>293.879756</td>\n",
       "      <td>832.579407</td>\n",
       "      <td>18.549963</td>\n",
       "      <td>530.060355</td>\n",
       "      <td>738.529738</td>\n",
       "      <td>0.100898</td>\n",
       "      <td>217.623321</td>\n",
       "      <td>0.362642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.918001</td>\n",
       "      <td>17504.900252</td>\n",
       "      <td>5.300020e+04</td>\n",
       "      <td>763.294264</td>\n",
       "      <td>1565.002978</td>\n",
       "      <td>2024.648567</td>\n",
       "      <td>152.336929</td>\n",
       "      <td>1.801112</td>\n",
       "      <td>1.801112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375355</td>\n",
       "      <td>1.018952</td>\n",
       "      <td>268.772507</td>\n",
       "      <td>517.372970</td>\n",
       "      <td>11.979641</td>\n",
       "      <td>285.538797</td>\n",
       "      <td>493.988324</td>\n",
       "      <td>0.301196</td>\n",
       "      <td>136.067764</td>\n",
       "      <td>0.931935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2011.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>2.680100e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>316.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.133484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2015.000000</td>\n",
       "      <td>16995.000000</td>\n",
       "      <td>4.593950e+04</td>\n",
       "      <td>424.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2548.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>777.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>818.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>0.286342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2016.000000</td>\n",
       "      <td>21842.500000</td>\n",
       "      <td>9.541525e+04</td>\n",
       "      <td>1109.000000</td>\n",
       "      <td>1047.000000</td>\n",
       "      <td>3574.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>527.000000</td>\n",
       "      <td>1335.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>1167.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>0.534548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2018.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1.442200e+06</td>\n",
       "      <td>10042.000000</td>\n",
       "      <td>14982.000000</td>\n",
       "      <td>17853.000000</td>\n",
       "      <td>2057.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>998.000000</td>\n",
       "      <td>1691.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1040.000000</td>\n",
       "      <td>1622.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>469.000000</td>\n",
       "      <td>56.135962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            year_is        price_fs      miles_fs  seller_comments_length  \\\n",
       "count  75056.000000    75056.000000  7.505600e+04            75056.000000   \n",
       "mean    2013.311434    17352.138510  6.510163e+04              660.293980   \n",
       "std        3.918001    17504.900252  5.300020e+04              763.294264   \n",
       "min     2000.000000      301.000000  0.000000e+00                0.000000   \n",
       "25%     2011.000000    11500.000000  2.680100e+04                0.000000   \n",
       "50%     2015.000000    16995.000000  4.593950e+04              424.000000   \n",
       "75%     2016.000000    21842.500000  9.541525e+04             1109.000000   \n",
       "max     2018.000000  1000000.000000  1.442200e+06            10042.000000   \n",
       "\n",
       "       options_length  features_length        dom_is   region_code  \\\n",
       "count    75056.000000     75056.000000  75056.000000  75056.000000   \n",
       "mean       746.204674      2380.702396     97.369204      4.942483   \n",
       "std       1565.002978      2024.648567    152.336929      1.801112   \n",
       "min          0.000000         0.000000      1.000000      2.000000   \n",
       "25%          0.000000       182.000000     24.000000      3.000000   \n",
       "50%          0.000000      2548.000000     54.000000      5.000000   \n",
       "75%       1047.000000      3574.000000    112.000000      6.000000   \n",
       "max      14982.000000     17853.000000   2057.000000      8.000000   \n",
       "\n",
       "          region_id  agi_stub      ...       doors_is_encoded  \\\n",
       "count  75056.000000   75056.0      ...           75056.000000   \n",
       "mean      94.942483      21.0      ...               1.896797   \n",
       "std        1.801112       0.0      ...               0.375355   \n",
       "min       92.000000      21.0      ...               0.000000   \n",
       "25%       93.000000      21.0      ...               2.000000   \n",
       "50%       95.000000      21.0      ...               2.000000   \n",
       "75%       96.000000      21.0      ...               2.000000   \n",
       "max       98.000000      21.0      ...               3.000000   \n",
       "\n",
       "       cylinders_is_encoded  interior_color_ss_encoded  \\\n",
       "count          75056.000000               75056.000000   \n",
       "mean               5.133074                 293.879756   \n",
       "std                1.018952                 268.772507   \n",
       "min                0.000000                   0.000000   \n",
       "25%                5.000000                   0.000000   \n",
       "50%                5.000000                 219.000000   \n",
       "75%                6.000000                 527.000000   \n",
       "max                6.000000                 998.000000   \n",
       "\n",
       "       exterior_color_ss_encoded  state_ss_encoded  county_encoded  \\\n",
       "count               75056.000000      75056.000000    75056.000000   \n",
       "mean                  832.579407         18.549963      530.060355   \n",
       "std                   517.372970         11.979641      285.538797   \n",
       "min                     0.000000          0.000000        0.000000   \n",
       "25%                   330.000000          6.000000      316.000000   \n",
       "50%                   777.000000         20.000000      532.000000   \n",
       "75%                  1335.000000         30.000000      787.000000   \n",
       "max                  1691.000000         40.000000     1040.000000   \n",
       "\n",
       "       fips_code_encoded  msa_type_encoded  msa_name_encoded        zscore  \n",
       "count       75056.000000      75056.000000      75056.000000  75056.000000  \n",
       "mean          738.529738          0.100898        217.623321      0.362642  \n",
       "std           493.988324          0.301196        136.067764      0.931935  \n",
       "min             0.000000          0.000000          0.000000      0.000008  \n",
       "25%           198.000000          0.000000         80.000000      0.133484  \n",
       "50%           818.000000          0.000000        224.000000      0.286342  \n",
       "75%          1167.000000          0.000000        332.000000      0.534548  \n",
       "max          1622.000000          1.000000        469.000000     56.135962  \n",
       "\n",
       "[8 rows x 46 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "listings['zscore'] = np.abs(stats.zscore(listings['price_fs']))\n",
    "listings.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231121    False\n",
       "66537     False\n",
       "144754    False\n",
       "232379    False\n",
       "172683    False\n",
       "12751     False\n",
       "14168     False\n",
       "27592     False\n",
       "27590     False\n",
       "27535     False\n",
       "27519     False\n",
       "27584     False\n",
       "27630     False\n",
       "27643     False\n",
       "27660     False\n",
       "27662     False\n",
       "27663     False\n",
       "27664     False\n",
       "27673     False\n",
       "27568     False\n",
       "27594     False\n",
       "266471    False\n",
       "214422    False\n",
       "27542     False\n",
       "251740    False\n",
       "258879    False\n",
       "160748    False\n",
       "210988    False\n",
       "272387    False\n",
       "144758    False\n",
       "          ...  \n",
       "183950    False\n",
       "227160    False\n",
       "34543     False\n",
       "226674    False\n",
       "184186    False\n",
       "227064    False\n",
       "227781    False\n",
       "272677    False\n",
       "183244    False\n",
       "149073    False\n",
       "183176    False\n",
       "183275    False\n",
       "182910    False\n",
       "182909    False\n",
       "182794    False\n",
       "228348    False\n",
       "183617    False\n",
       "183737    False\n",
       "183642    False\n",
       "111073    False\n",
       "184687    False\n",
       "114491    False\n",
       "184620    False\n",
       "20267     False\n",
       "115145    False\n",
       "272843    False\n",
       "20364     False\n",
       "184515    False\n",
       "184554    False\n",
       "184606    False\n",
       "Name: outlier, Length: 75056, dtype: bool"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Create Outlier column\n",
    "listings['outlier'] = listings['zscore'] > 3\n",
    "\n",
    "listings['outlier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_is</th>\n",
       "      <th>price_fs</th>\n",
       "      <th>miles_fs</th>\n",
       "      <th>seller_comments_length</th>\n",
       "      <th>options_length</th>\n",
       "      <th>features_length</th>\n",
       "      <th>dom_is</th>\n",
       "      <th>region_code</th>\n",
       "      <th>region_id</th>\n",
       "      <th>agi_stub</th>\n",
       "      <th>...</th>\n",
       "      <th>doors_is_encoded</th>\n",
       "      <th>cylinders_is_encoded</th>\n",
       "      <th>interior_color_ss_encoded</th>\n",
       "      <th>exterior_color_ss_encoded</th>\n",
       "      <th>state_ss_encoded</th>\n",
       "      <th>county_encoded</th>\n",
       "      <th>fips_code_encoded</th>\n",
       "      <th>msa_type_encoded</th>\n",
       "      <th>msa_name_encoded</th>\n",
       "      <th>zscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>75025.000000</td>\n",
       "      <td>75025.000000</td>\n",
       "      <td>7.502500e+04</td>\n",
       "      <td>75025.000000</td>\n",
       "      <td>75025.000000</td>\n",
       "      <td>75025.000000</td>\n",
       "      <td>75025.000000</td>\n",
       "      <td>75025.000000</td>\n",
       "      <td>75025.000000</td>\n",
       "      <td>75025.0</td>\n",
       "      <td>...</td>\n",
       "      <td>75025.000000</td>\n",
       "      <td>75025.000000</td>\n",
       "      <td>75025.000000</td>\n",
       "      <td>75025.000000</td>\n",
       "      <td>75025.000000</td>\n",
       "      <td>75025.000000</td>\n",
       "      <td>75025.000000</td>\n",
       "      <td>75025.000000</td>\n",
       "      <td>75025.000000</td>\n",
       "      <td>75025.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2013.312776</td>\n",
       "      <td>17086.118827</td>\n",
       "      <td>6.508791e+04</td>\n",
       "      <td>660.350896</td>\n",
       "      <td>746.490530</td>\n",
       "      <td>2380.489530</td>\n",
       "      <td>97.351390</td>\n",
       "      <td>4.943086</td>\n",
       "      <td>94.943086</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.896808</td>\n",
       "      <td>5.133076</td>\n",
       "      <td>293.976794</td>\n",
       "      <td>832.639214</td>\n",
       "      <td>18.550297</td>\n",
       "      <td>530.084505</td>\n",
       "      <td>738.575701</td>\n",
       "      <td>0.100860</td>\n",
       "      <td>217.666005</td>\n",
       "      <td>0.347595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.917482</td>\n",
       "      <td>7692.683039</td>\n",
       "      <td>5.299954e+04</td>\n",
       "      <td>763.400546</td>\n",
       "      <td>1565.251365</td>\n",
       "      <td>2024.834597</td>\n",
       "      <td>152.314161</td>\n",
       "      <td>1.800797</td>\n",
       "      <td>1.800797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375335</td>\n",
       "      <td>1.018944</td>\n",
       "      <td>268.769999</td>\n",
       "      <td>517.371152</td>\n",
       "      <td>11.980266</td>\n",
       "      <td>285.545988</td>\n",
       "      <td>494.036142</td>\n",
       "      <td>0.301145</td>\n",
       "      <td>136.050532</td>\n",
       "      <td>0.269320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2011.000000</td>\n",
       "      <td>11500.000000</td>\n",
       "      <td>2.679600e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>315.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.133270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2015.000000</td>\n",
       "      <td>16995.000000</td>\n",
       "      <td>4.592500e+04</td>\n",
       "      <td>423.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2548.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>777.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>818.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>0.285857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2016.000000</td>\n",
       "      <td>21817.000000</td>\n",
       "      <td>9.536200e+04</td>\n",
       "      <td>1110.000000</td>\n",
       "      <td>1048.000000</td>\n",
       "      <td>3574.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>527.000000</td>\n",
       "      <td>1335.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>1167.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>0.534548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2018.000000</td>\n",
       "      <td>69706.000000</td>\n",
       "      <td>1.442200e+06</td>\n",
       "      <td>10042.000000</td>\n",
       "      <td>14982.000000</td>\n",
       "      <td>17853.000000</td>\n",
       "      <td>2057.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>998.000000</td>\n",
       "      <td>1691.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1040.000000</td>\n",
       "      <td>1622.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>469.000000</td>\n",
       "      <td>2.990832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            year_is      price_fs      miles_fs  seller_comments_length  \\\n",
       "count  75025.000000  75025.000000  7.502500e+04            75025.000000   \n",
       "mean    2013.312776  17086.118827  6.508791e+04              660.350896   \n",
       "std        3.917482   7692.683039  5.299954e+04              763.400546   \n",
       "min     2000.000000    301.000000  0.000000e+00                0.000000   \n",
       "25%     2011.000000  11500.000000  2.679600e+04                0.000000   \n",
       "50%     2015.000000  16995.000000  4.592500e+04              423.000000   \n",
       "75%     2016.000000  21817.000000  9.536200e+04             1110.000000   \n",
       "max     2018.000000  69706.000000  1.442200e+06            10042.000000   \n",
       "\n",
       "       options_length  features_length        dom_is   region_code  \\\n",
       "count    75025.000000     75025.000000  75025.000000  75025.000000   \n",
       "mean       746.490530      2380.489530     97.351390      4.943086   \n",
       "std       1565.251365      2024.834597    152.314161      1.800797   \n",
       "min          0.000000         0.000000      1.000000      2.000000   \n",
       "25%          0.000000       182.000000     24.000000      3.000000   \n",
       "50%          0.000000      2548.000000     54.000000      5.000000   \n",
       "75%       1048.000000      3574.000000    112.000000      6.000000   \n",
       "max      14982.000000     17853.000000   2057.000000      8.000000   \n",
       "\n",
       "          region_id  agi_stub      ...       doors_is_encoded  \\\n",
       "count  75025.000000   75025.0      ...           75025.000000   \n",
       "mean      94.943086      21.0      ...               1.896808   \n",
       "std        1.800797       0.0      ...               0.375335   \n",
       "min       92.000000      21.0      ...               0.000000   \n",
       "25%       93.000000      21.0      ...               2.000000   \n",
       "50%       95.000000      21.0      ...               2.000000   \n",
       "75%       96.000000      21.0      ...               2.000000   \n",
       "max       98.000000      21.0      ...               3.000000   \n",
       "\n",
       "       cylinders_is_encoded  interior_color_ss_encoded  \\\n",
       "count          75025.000000               75025.000000   \n",
       "mean               5.133076                 293.976794   \n",
       "std                1.018944                 268.769999   \n",
       "min                0.000000                   0.000000   \n",
       "25%                5.000000                   0.000000   \n",
       "50%                5.000000                 219.000000   \n",
       "75%                6.000000                 527.000000   \n",
       "max                6.000000                 998.000000   \n",
       "\n",
       "       exterior_color_ss_encoded  state_ss_encoded  county_encoded  \\\n",
       "count               75025.000000      75025.000000    75025.000000   \n",
       "mean                  832.639214         18.550297      530.084505   \n",
       "std                   517.371152         11.980266      285.545988   \n",
       "min                     0.000000          0.000000        0.000000   \n",
       "25%                   330.000000          6.000000      315.000000   \n",
       "50%                   777.000000         20.000000      532.000000   \n",
       "75%                  1335.000000         30.000000      787.000000   \n",
       "max                  1691.000000         40.000000     1040.000000   \n",
       "\n",
       "       fips_code_encoded  msa_type_encoded  msa_name_encoded        zscore  \n",
       "count       75025.000000      75025.000000      75025.000000  75025.000000  \n",
       "mean          738.575701          0.100860        217.666005      0.347595  \n",
       "std           494.036142          0.301145        136.050532      0.269320  \n",
       "min             0.000000          0.000000          0.000000      0.000008  \n",
       "25%           198.000000          0.000000         80.000000      0.133270  \n",
       "50%           818.000000          0.000000        224.000000      0.285857  \n",
       "75%          1167.000000          0.000000        332.000000      0.534548  \n",
       "max          1622.000000          1.000000        469.000000      2.990832  \n",
       "\n",
       "[8 rows x 46 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop outliers\n",
    "\n",
    "listings = listings.drop(listings[listings.outlier == True].index)\n",
    "\n",
    "listings.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save dataframe output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "listings.to_pickle(\"Second_Analysis_Pickle.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
